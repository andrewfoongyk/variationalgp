{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import pickle\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../boston_housing0.pkl','rb') as handle:\n",
    "    train_set, train_set_normalised, val_set_normalised, test_set, train_mean, train_sd = pickle.load(handle)\n",
    "\n",
    "Xn = train_set_normalised[:,:-1]\n",
    "Yn = np.expand_dims(train_set_normalised[:,-1],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "class variational_GP(nn.Module):\n",
    "    \n",
    "    def __init__(self, Xn, Yn):   # the GP takes the training data as arguments, in the form of numpy arrays, with the correct dimensions\n",
    "        \n",
    "        super().__init__()\n",
    "        # initialise hyperparameters\n",
    "        self.Xn = torch.tensor(Xn).type(torch.FloatTensor)\n",
    "        self.Yn = torch.tensor(Yn).type(torch.FloatTensor)\n",
    "        self.Xm = nn.Parameter(self.Xn[:20].type(torch.FloatTensor)) # still have to select randomly!!! Not yet because deterministic makes debugging easier\n",
    "        self.no_inputs = Xn.shape[1]\n",
    "        self.logsigmaf2 = nn.Parameter(torch.Tensor([0])) # function variance\n",
    "        self.logl2 = nn.Parameter(torch.zeros(self.no_inputs)) # horizontal length scales\n",
    "        self.logsigman2 = nn.Parameter(torch.Tensor([0])) # noise variance\n",
    "        \n",
    "    def get_K(self,inputs1,inputs2):\n",
    "        \n",
    "        inputs1_col = torch.unsqueeze(inputs1.transpose(0,1), 2)\n",
    "        inputs2_row = torch.unsqueeze(inputs2.transpose(0,1), 1)\n",
    "        squared_distances = (inputs1_col - inputs2_row)**2        \n",
    "        length_factors = (1/(2*torch.exp(self.logl2))).reshape(self.no_inputs,1,1)\n",
    "        K = torch.exp(self.logsigmaf2) * torch.exp(-torch.sum(length_factors * squared_distances, 0))\n",
    "        return(K)\n",
    "    \n",
    "    def Fv_inv(self): # All the necessary arguments are instance variables, so no need to pass them\n",
    "\n",
    "        Knn = self.get_K(self.Xn,self.Xn)\n",
    "        Kmm = self.get_K(self.Xm,self.Xm)\n",
    "        Kmn = self.get_K(self.Xm,self.Xn)\n",
    "        Knm = Kmn.transpose(0,1)\n",
    "        # Compute first term (log marginal likelihood) NEED TO CHECK WHETHER THIS DERIVATION IS CORRECT\n",
    "        M = Kmm + 1/torch.exp(self.logsigman2) * torch.mm(Kmn,Knm)\n",
    "        L_M = torch.cholesky(M)\n",
    "        b_M, _ = torch.gesv(torch.mm(Kmn,self.Yn),L_M)\n",
    "        log_marg = (-Xn.shape[0]/2*torch.log(2*np.pi*torch.exp(self.logsigman2)) \n",
    "                    - 1/torch.exp(self.logsigman2)*torch.mm(self.Yn.transpose(0,1),self.Yn) \n",
    "                    - 1/torch.exp(self.logsigman2)**2 * torch.mm(b_M.transpose(0,1),b_M))\n",
    "        # Compute second term (trace, regularizer) USING INVERSE TEMPORARILY. NEED TO CHECK WHETHER WE CAN DO GRADIENTS THROUGH NON-SQUARE SYSTEM OF EQUATIONS\n",
    "        reg = - 1/torch.exp(self.logsigman2) * torch.trace(Knn - torch.mm(torch.mm(Knm, torch.inverse(Kmm)), Kmn))\n",
    "\n",
    "        return(log_marg + reg)\n",
    "    \n",
    "    def optimize_parameters(self,no_iters,method):\n",
    "        \n",
    "        # Set criterion and optimizer FOR NOW I'M GONNA USE ADAM ONLY\n",
    "        '''if method == 'BFGS':\n",
    "            optimizer = optim.LBFGS(self.parameters(), lr=1)  \n",
    "        elif method == 'Adam':\n",
    "            optimizer = optim.Adam(self.parameters(), lr=0.001)\n",
    "        else: \n",
    "            sys.exit('method must be either \\'BFGS\\' or \\'Adam\\'') # An exception would be better\n",
    "        \n",
    "        for iteration in range(no_iters):\n",
    "            optimizer.zero_grad()\n",
    "            loss = self.Fv_inv() # Forward\n",
    "            loss.backward() # Backward\n",
    "            optimizer.step() # Optimize'''\n",
    "            \n",
    "        optimizer = optim.Adam(self.parameters(), lr=0.001)\n",
    "        for iteration in range(no_iters):\n",
    "            optimizer.zero_grad()\n",
    "            loss = -self.Fv_inv() # Forward. Negate because we want to maximize\n",
    "            loss.backward() # Backward\n",
    "            optimizer.step() # Optimize\n",
    "            \n",
    "            if iteration%50 == 0:\n",
    "                print(iteration,-loss)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "myGP = variational_GP(Xn, Yn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After optimization, the variational lower bound has been maximized and the parameters have changed.\n",
    "\n",
    "### Before:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       requires_grad=True)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "myGP.logl2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([0.], requires_grad=True)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "myGP.logsigmaf2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([0.], requires_grad=True)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "myGP.logsigman2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[-4.1617e-01, -4.8207e-01, -1.1784e+00, -2.7964e-01, -8.3184e-01,\n",
       "          5.6842e-02, -1.8585e+00,  6.8051e-01, -6.4458e-01,  1.2854e-01,\n",
       "         -7.3106e-01,  2.1191e-01, -7.4717e-01],\n",
       "        [ 6.4197e-01, -4.8207e-01,  1.0148e+00, -2.7964e-01,  6.4102e-01,\n",
       "         -1.0660e-01,  1.1091e+00, -1.2244e+00,  1.6485e+00,  1.5426e+00,\n",
       "          7.9477e-01,  1.1444e-01, -4.3881e-01],\n",
       "        [-4.1075e-01, -4.8207e-01,  3.9342e-01,  3.5760e+00, -5.6652e-02,\n",
       "          1.1272e-01,  8.3674e-01, -1.9121e-01, -5.2992e-01, -7.9420e-01,\n",
       "         -9.6224e-01,  4.1126e-01, -3.0223e-01],\n",
       "        [ 2.4395e+00, -4.8207e-01,  1.0148e+00, -2.7964e-01,  1.1750e+00,\n",
       "         -1.3178e+00,  9.6577e-01, -9.7308e-01,  1.6485e+00,  1.5426e+00,\n",
       "          7.9477e-01,  4.4526e-01,  1.0030e+00],\n",
       "        [-4.1742e-01, -4.8207e-01,  2.3697e-01, -2.7964e-01, -1.0299e+00,\n",
       "         -8.4250e-02, -5.5033e-01,  5.8610e-01, -5.2992e-01, -6.3198e-02,\n",
       "          1.0121e-01,  3.3230e-01, -4.3145e-02],\n",
       "        [-3.5150e-01, -4.8207e-01, -4.5524e-01, -2.7964e-01, -1.6001e-01,\n",
       "         -6.4024e-01, -4.4997e-01,  3.4337e-01, -6.4458e-01, -6.0846e-01,\n",
       "          1.1647e+00,  4.3149e-01, -5.8806e-01],\n",
       "        [ 1.3436e-01, -4.8207e-01,  1.0148e+00, -2.7964e-01,  2.2758e-01,\n",
       "         -5.4105e-01, -5.6825e-01, -2.9056e-01,  1.6485e+00,  1.5426e+00,\n",
       "          7.9477e-01,  3.5188e-01, -1.6846e-01],\n",
       "        [-4.1683e-01, -4.8207e-01, -8.9064e-01, -2.7964e-01, -3.5811e-01,\n",
       "         -4.5305e-01, -3.7829e-01,  4.9103e-01, -5.2992e-01, -1.1058e+00,\n",
       "          7.9477e-01,  4.4526e-01, -4.7260e-01],\n",
       "        [-1.1966e-01, -4.8207e-01, -1.9548e-01, -2.7964e-01, -1.0833e-01,\n",
       "         -1.8430e+00, -1.1202e+00, -5.8857e-01, -6.4458e-01, -6.2643e-01,\n",
       "         -3.7498e-02, -5.4464e-02, -9.0363e-04],\n",
       "        [-3.9752e-01, -4.8207e-01, -3.9325e-01, -2.7964e-01, -3.1505e-01,\n",
       "          1.5742e-01,  5.8585e-01, -4.9661e-01, -5.2992e-01, -1.4708e-01,\n",
       "          1.1184e+00, -3.0630e+00, -2.8392e-01],\n",
       "        [ 8.0659e+00, -4.8207e-01,  1.0148e+00, -2.7964e-01,  1.0544e+00,\n",
       "         -4.6841e-01,  1.1091e+00, -9.2609e-01,  1.6485e+00,  1.5426e+00,\n",
       "          7.9477e-01, -3.6477e+00,  1.1227e+00],\n",
       "        [ 1.1983e+00, -4.8207e-01,  1.0148e+00, -2.7964e-01,  3.4817e-01,\n",
       "          5.0946e-01,  1.1091e+00, -1.0556e+00,  1.6485e+00,  1.5426e+00,\n",
       "          7.9477e-01, -3.4476e+00,  1.2072e+00],\n",
       "        [ 3.0205e-01, -4.8207e-01,  1.0148e+00, -2.7964e-01,  1.5799e+00,\n",
       "          6.8018e-02,  9.8010e-01, -7.9924e-01,  1.6485e+00,  1.5426e+00,\n",
       "          7.9477e-01, -4.0346e-01,  7.2424e-01],\n",
       "        [ 2.3924e+00, -4.8207e-01,  1.0148e+00, -2.7964e-01,  1.2353e+00,\n",
       "         -2.2914e+00,  1.1091e+00, -1.0840e+00,  1.6485e+00,  1.5426e+00,\n",
       "          7.9477e-01,  4.4526e-01,  2.2013e+00],\n",
       "        [-2.1222e-01, -4.8207e-01,  1.2332e+00,  3.5760e+00,  4.1707e-01,\n",
       "          2.1090e+00,  1.0446e+00, -8.1398e-01, -5.2992e-01, -3.3238e-02,\n",
       "         -1.7483e+00,  3.6683e-01, -1.5103e+00],\n",
       "        [-4.1752e-01,  2.5475e+00, -1.3260e+00, -2.7964e-01, -1.3486e+00,\n",
       "          1.0459e+00, -2.1166e+00,  1.9110e+00, -5.2992e-01, -3.0287e-01,\n",
       "         -1.7020e+00,  1.7286e-01, -1.1133e+00],\n",
       "        [ 2.4847e-01, -4.8207e-01,  1.0148e+00, -2.7964e-01, -2.1169e-01,\n",
       "         -7.0281e-02, -1.5607e-01, -1.6253e-01,  1.6485e+00,  1.5426e+00,\n",
       "          7.9477e-01,  4.4526e-01, -2.6843e-01],\n",
       "        [-4.1930e-01,  2.9803e+00, -1.4323e+00, -2.7964e-01, -1.3142e+00,\n",
       "          1.3895e+00, -1.2528e+00,  1.6667e+00, -8.7388e-01, -4.7664e-01,\n",
       "         -2.7193e+00,  4.4526e-01, -1.2062e+00],\n",
       "        [-4.1624e-01, -4.8207e-01, -1.0589e+00, -2.7964e-01, -4.0118e-01,\n",
       "          3.5439e-01, -1.2887e+00, -2.9998e-01, -5.2992e-01, -6.7437e-01,\n",
       "         -8.6977e-01,  3.8135e-01, -1.0302e+00],\n",
       "        [-4.1468e-01, -4.8207e-01, -7.7699e-01, -2.7964e-01, -4.9592e-01,\n",
       "         -6.1789e-01, -9.8760e-01,  7.7612e-02, -5.2992e-01, -7.7623e-01,\n",
       "          3.3240e-01,  4.4526e-01, -5.4582e-01]], requires_grad=True)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "myGP.Xm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-1175.5045]], grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "myGP.Fv_inv()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### During:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 tensor([[-1175.5045]], grad_fn=<NegBackward>)\n",
      "50 tensor([[-1117.4366]], grad_fn=<NegBackward>)\n",
      "100 tensor([[-1067.2606]], grad_fn=<NegBackward>)\n",
      "150 tensor([[-1024.8361]], grad_fn=<NegBackward>)\n",
      "200 tensor([[-989.4432]], grad_fn=<NegBackward>)\n",
      "250 tensor([[-959.8486]], grad_fn=<NegBackward>)\n",
      "300 tensor([[-934.8455]], grad_fn=<NegBackward>)\n",
      "350 tensor([[-913.4968]], grad_fn=<NegBackward>)\n",
      "400 tensor([[-895.0981]], grad_fn=<NegBackward>)\n",
      "450 tensor([[-879.1000]], grad_fn=<NegBackward>)\n",
      "500 tensor([[-865.0749]], grad_fn=<NegBackward>)\n",
      "550 tensor([[-852.7040]], grad_fn=<NegBackward>)\n",
      "600 tensor([[-841.7478]], grad_fn=<NegBackward>)\n",
      "650 tensor([[-832.0123]], grad_fn=<NegBackward>)\n",
      "700 tensor([[-823.3337]], grad_fn=<NegBackward>)\n",
      "750 tensor([[-815.5717]], grad_fn=<NegBackward>)\n",
      "800 tensor([[-808.6042]], grad_fn=<NegBackward>)\n",
      "850 tensor([[-802.3282]], grad_fn=<NegBackward>)\n",
      "900 tensor([[-796.6624]], grad_fn=<NegBackward>)\n",
      "950 tensor([[-791.5453]], grad_fn=<NegBackward>)\n"
     ]
    }
   ],
   "source": [
    "myGP.optimize_parameters(1000,'Adam')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### After:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-786.9269]], grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "myGP.Fv_inv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([-0.4345,  0.3736,  0.8932, -1.2515,  0.3020,  0.5562,  1.1750,  0.9067,\n",
       "         0.0639,  0.9367,  0.9518,  0.1942,  0.7956], requires_grad=True)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "myGP.logl2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([-0.6762], requires_grad=True)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "myGP.logsigmaf2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([0.6132], requires_grad=True)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "myGP.logsigman2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[-4.0936e-01,  3.8031e-01, -7.7444e-01, -2.7968e-01, -1.0194e+00,\n",
       "         -3.1617e-01, -9.9130e-01,  1.4040e+00, -5.0853e-01, -5.5842e-01,\n",
       "         -4.0630e-02,  3.6491e-01, -3.3373e-01],\n",
       "        [ 4.6075e-01, -4.8217e-01,  1.0173e+00, -2.7962e-01,  1.0092e+00,\n",
       "         -9.2791e-01,  8.4620e-01, -9.1865e-01,  1.6901e+00,  1.5693e+00,\n",
       "          7.9101e-01,  1.5224e-01, -2.3590e-01],\n",
       "        [-3.9629e-01, -4.2300e-01, -1.7654e-01,  3.5760e+00, -4.5328e-01,\n",
       "         -3.1476e-01,  2.1852e-01, -7.8552e-02, -5.1014e-01, -7.6552e-01,\n",
       "         -3.0363e-01,  3.7151e-01,  3.4788e-01],\n",
       "        [ 2.7636e+00, -1.1234e+00,  4.5490e-01,  6.4649e-01,  1.6336e+00,\n",
       "         -1.6187e+00,  4.5393e-01, -4.2708e-01,  2.4173e+00,  2.1012e+00,\n",
       "          2.4808e-01,  9.1641e-01,  6.4435e-01],\n",
       "        [-4.0686e-01, -4.3723e-01,  5.5187e-02, -2.7966e-01, -8.2693e-01,\n",
       "         -3.1143e-01, -1.0846e+00,  3.5556e-01, -6.2159e-01, -4.5610e-01,\n",
       "         -2.2684e-01,  3.7449e-01, -3.2612e-01],\n",
       "        [-3.9499e-01, -4.4516e-01, -6.9298e-01, -2.7961e-01, -5.7225e-01,\n",
       "         -2.5713e-01, -8.1268e-01,  4.6341e-01, -6.3129e-01, -8.1279e-01,\n",
       "          4.8090e-01,  3.8481e-01, -4.8243e-01],\n",
       "        [-3.1742e-02, -4.8203e-01,  1.0088e+00, -2.7964e-01,  2.1901e-01,\n",
       "         -5.7233e-01, -6.6310e-01, -5.8545e-02,  1.6209e+00,  1.5241e+00,\n",
       "          7.9705e-01,  1.6515e-01,  1.4486e-01],\n",
       "        [-3.8839e-01, -4.4203e-01, -3.3694e-01, -2.7963e-01, -2.3326e-01,\n",
       "          8.0737e-02,  2.7131e-01, -2.2958e-01, -5.7859e-01, -4.8993e-01,\n",
       "          3.5109e-01,  3.8316e-01, -2.7090e-01],\n",
       "        [-3.9878e-01, -3.0915e-01, -7.2192e-01, -2.7883e-01,  1.5308e-01,\n",
       "         -8.0873e-01, -1.2133e+00, -8.7367e-01, -3.2183e-01, -2.6341e-01,\n",
       "         -3.9470e-01,  4.3524e-01, -4.8379e-01],\n",
       "        [-8.9848e-01,  2.7719e-01, -7.0987e-01,  8.3618e-01, -6.9119e-01,\n",
       "          4.8367e-01,  3.0636e-01, -7.6447e-01, -1.0189e+00,  1.7239e-01,\n",
       "          1.6187e+00, -3.3643e+00, -5.4832e-01],\n",
       "        [ 8.3119e+00, -1.0911e+00,  1.0148e+00,  6.2945e-01,  1.3047e+00,\n",
       "         -2.0555e-01,  1.5279e+00, -6.9383e-01,  1.6485e+00,  1.5426e+00,\n",
       "          2.7035e-01, -3.9932e+00,  1.3179e+00],\n",
       "        [ 1.6766e+00, -1.1149e+00,  4.5351e-01,  6.1169e-01, -4.5232e-03,\n",
       "          8.5081e-01,  1.4149e+00, -1.4024e+00,  2.3996e+00,  2.1034e+00,\n",
       "          2.4673e-01, -3.0259e+00,  8.5990e-01],\n",
       "        [-1.0375e-01, -4.8139e-01,  1.0065e+00, -2.7963e-01,  1.6955e+00,\n",
       "          1.6231e-01,  6.5402e-01, -5.4386e-01,  1.7249e+00,  1.5856e+00,\n",
       "          7.7597e-01,  1.8615e-01,  1.5491e-01],\n",
       "        [ 2.7729e+00, -1.1575e+00,  4.0963e-01,  6.5685e-01,  1.7884e+00,\n",
       "         -2.6270e+00,  5.0258e-01, -5.0405e-01,  2.4433e+00,  2.1467e+00,\n",
       "          2.0689e-01,  9.8705e-01,  1.8440e+00],\n",
       "        [ 7.7530e-01, -1.3090e+00,  1.6004e+00,  4.0173e+00,  1.0578e+00,\n",
       "          2.5145e+00,  1.3825e+00, -1.5808e+00, -1.3577e+00,  6.8896e-01,\n",
       "         -2.1954e+00,  8.5547e-01, -1.9279e+00],\n",
       "        [ 5.4218e-01,  2.7428e+00, -1.8551e+00, -1.3792e+00, -1.8012e+00,\n",
       "          8.1128e-01, -2.3834e+00,  2.1764e+00,  2.8494e-01,  1.1461e-01,\n",
       "         -2.0373e+00, -4.2561e-01, -8.9146e-01],\n",
       "        [ 2.9442e-01, -4.8184e-01,  1.0124e+00, -2.7964e-01,  1.3657e-01,\n",
       "          3.8412e-01,  2.9366e-01, -3.4764e-01,  1.6482e+00,  1.5406e+00,\n",
       "          7.8910e-01,  3.6245e-01, -1.5160e-01],\n",
       "        [ 6.2253e-01,  2.7714e+00, -1.9599e+00, -1.4477e+00, -1.9614e+00,\n",
       "          1.1065e+00, -2.0288e+00,  1.9648e+00, -5.8904e-02, -1.2465e-01,\n",
       "         -3.0834e+00, -2.3139e-01, -1.0089e+00],\n",
       "        [-1.2463e+00, -8.0242e-01, -1.5911e+00, -1.2959e+00, -6.4296e-02,\n",
       "          6.7698e-02, -1.6526e+00, -4.1764e-01, -1.3774e+00, -3.2883e-01,\n",
       "         -1.2104e+00, -3.1760e-01, -7.1045e-01],\n",
       "        [-4.0221e-01, -3.8042e-01, -7.2511e-01, -2.7959e-01, -6.1130e-01,\n",
       "         -3.1953e-01, -3.6587e-01,  3.8426e-01, -6.4120e-01, -7.9376e-01,\n",
       "         -2.2320e-01,  3.8106e-01, -1.9349e-01]], requires_grad=True)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "myGP.Xm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next step: get posterior, predictive distribution, and plot how it changes during training, to see that the algorithm is working."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
